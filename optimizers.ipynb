{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a5db970-86d1-4358-8b0f-6d965ee7cf3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Q-1 part-1 understandings the optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffddabb-0a68-424a-a9cb-8e46e5703913",
   "metadata": {},
   "outputs": [],
   "source": [
    "^1 The role of optimization algorithms in artificial neural networks (ANNs) is to adjust the model's parameters iteratively during the training process. These algorithms aim to find the optimal set of weights and biases that minimize a predefined loss function, allowing the neural network to make accurate predictions.\n",
    "\n",
    " Optimization algorithms are necessary in ANNs due to the complexity of the parameter space. Neural networks often have a large number of parameters, and manually fine-tuning them to achieve optimal performance is impractical. Optimization algorithms automate this process, searching through the parameter space to find the values that minimize the prediction error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc75991-9e4c-44cc-88e1-2dc583d77e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "2)Gradient descent is a fundamental optimization algorithm used in training artificial neural networks. The basic idea is to iteratively adjust the model parameters in the direction opposite to the gradient of the loss function with respect to those parameters. This process continues until a minimum of the loss function is reached, indicating optimal parameter values.\n",
    "\n",
    "There are several variants of gradient descent, each with its own characteristics:\n",
    "\n",
    "Batch Gradient Descent (BGD): In BGD, the entire dataset is used to compute the gradient of the loss function, and a single update is made to the model parameters. BGD often provides a smooth convergence but can be computationally expensive, especially with large datasets, as it requires storing the entire dataset in memory.\n",
    "\n",
    "Stochastic Gradient Descent (SGD): SGD updates the parameters using only a single randomly chosen data point at a time. This reduces memory requirements but introduces more noise into the parameter updates. While the noisy updates can help escape local minima, convergence may be less smooth compared to BGD.\n",
    "\n",
    "Mini-Batch Gradient Descent: Mini-batch gradient descent strikes a balance by updating the parameters using a small randomly selected subset (mini-batch) of the dataset. It combines some advantages of both BGD and SGD, reducing memory requirements and providing a balance between smoothness and noise in the convergence.\n",
    "\n",
    " The differences and tradeoffs among these variants lie in terms of convergence speed and memory requirements:\n",
    "\n",
    "Convergence Speed: BGD can have a smoother convergence since it considers the entire dataset in each update, but it might be computationally expensive, especially with large datasets. SGD and mini-batch gradient descent can converge faster on average because they update parameters more frequently, but the convergence path may be noisier.\n",
    "\n",
    "Memory Requirements: BGD requires storing the entire dataset in memory for each update, which can be challenging with large datasets. SGD and mini-batch gradient descent alleviate this issue by processing only a subset of the data, making them more memory-efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12e331d-eb63-41c7-bc88-152f3ad9430b",
   "metadata": {},
   "outputs": [],
   "source": [
    "3)Traditional gradient descent optimization methods face several challenges that can impede their efficiency and effectiveness. Some of these challenges include:\n",
    "\n",
    "Slow Convergence:\n",
    "\n",
    "Issue: Gradient descent can converge slowly, especially when the cost function has long, narrow valleys.\n",
    "Explanation: In such cases, the gradient points in the direction of the valley, but progress is slow because the steps are primarily perpendicular to the direction of the valley.\n",
    "Solution: Modern optimizers often use adaptive learning rates that dynamically adjust the step size for each parameter. Algorithms like AdaGrad, RMSprop, and Adam help in speeding up convergence by allowing larger steps in less varying directions.\n",
    "Local Minima:\n",
    "\n",
    "Issue: Getting stuck in local minima can prevent the algorithm from finding the global minimum of the cost function.\n",
    "Explanation: Traditional gradient descent is prone to converge to local minima, especially in complex, non-convex optimization landscapes.\n",
    "Solution: Stochastic methods and mini-batch variations can help escape local minima. Additionally, more sophisticated optimization algorithms, such as Adam and stochastic gradient descent with momentum, can mitigate this issue by incorporating momentum terms.\n",
    "Sensitivity to Initial Conditions:\n",
    "\n",
    "Issue: Convergence may depend on the initial values of the parameters, making the optimization sensitive to the starting point.\n",
    "Explanation: In some cases, the optimization may get trapped in a suboptimal region due to poor initialization.\n",
    "Solution: Some modern optimizers use techniques like weight initialization and batch normalization to alleviate sensitivity to initial conditions. These methods help maintain stable and consistent learning throughout the training process.\n",
    "High Computational Requirements:\n",
    "\n",
    "Issue: Computationally expensive, especially when dealing with large datasets and complex models.\n",
    "Explanation: Traditional gradient descent requires computing the gradient over the entire dataset for each iteration.\n",
    "Solution: Stochastic Gradient Descent (SGD) and its variants, such as mini-batch SGD, compute the gradient on a subset of the data, reducing computational requirements and accelerating convergence.\n",
    "Learning Rate Tuning:\n",
    "\n",
    "Issue: Choosing an appropriate learning rate can be challenging.\n",
    "Explanation: Too large a learning rate can lead to oscillations or divergence, while too small a learning rate can cause slow convergence.\n",
    "Solution: Adaptive learning rate methods dynamically adjust the learning rate during training. Techniques like learning rate schedules, momentum, and adaptive optimizers (e.g., Adam) can help overcome this challenge.\n",
    "Modern optimizers address these challenges by incorporating adaptive learning rates, momentum terms, and other techniques to make the optimization process more robust and efficient across various types of cost landscapes. These advancements have significantly improved the training of deep neural networks and other machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ef80fe-e088-460e-b289-f37f0f2ed95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "4)Momentum and learning rate are two crucial concepts in optimization algorithms, particularly in the context of training machine learning models. They play a significant role in influencing the convergence behavior and overall performance of optimization processes.\n",
    "\n",
    "Momentum:\n",
    "Definition: Momentum is a technique used to accelerate convergence, especially in the presence of shallow valleys, plateaus, or noisy gradients. It introduces a moving average of past gradients to the optimization process.\n",
    "\n",
    "Impact on Convergence:\n",
    "\n",
    "Smoothing Effect: Momentum helps smooth out variations in the gradient by taking into account the historical gradients. This smoothing effect allows the optimizer to continue moving in the same direction, even if the current gradient is noisy or oscillates.\n",
    "Acceleration: By accumulating momentum, the optimization process gains speed, which is especially beneficial when navigating through regions with flat or slowly changing gradients.\n",
    "Equation:\n",
    "�\n",
    "�\n",
    "=\n",
    "�\n",
    "⋅\n",
    "�\n",
    "�\n",
    "−\n",
    "1\n",
    "+\n",
    "(\n",
    "1\n",
    "−\n",
    "�\n",
    ")\n",
    "⋅\n",
    "∇\n",
    "�\n",
    "(\n",
    "�\n",
    "�\n",
    ")\n",
    "v \n",
    "t\n",
    "​\n",
    " =β⋅v \n",
    "t−1\n",
    "​\n",
    " +(1−β)⋅∇J(θ \n",
    "t\n",
    "​\n",
    " )\n",
    "�\n",
    "�\n",
    "+\n",
    "1\n",
    "=\n",
    "�\n",
    "�\n",
    "−\n",
    "�\n",
    "⋅\n",
    "�\n",
    "�\n",
    "θ \n",
    "t+1\n",
    "​\n",
    " =θ \n",
    "t\n",
    "​\n",
    " −α⋅v \n",
    "t\n",
    "​\n",
    " \n",
    "\n",
    "where:\n",
    "\n",
    "�\n",
    "�\n",
    "v \n",
    "t\n",
    "​\n",
    "  is the momentum at time step \n",
    "�\n",
    "t,\n",
    "�\n",
    "β is the momentum parameter (typically between 0 and 1),\n",
    "∇\n",
    "�\n",
    "(\n",
    "�\n",
    "�\n",
    ")\n",
    "∇J(θ \n",
    "t\n",
    "​\n",
    " ) is the gradient of the cost function at time step \n",
    "�\n",
    "t,\n",
    "�\n",
    "α is the learning rate,\n",
    "�\n",
    "�\n",
    "θ \n",
    "t\n",
    "​\n",
    "  is the parameter vector at time step \n",
    "�\n",
    "t.\n",
    "Learning Rate:\n",
    "Definition: The learning rate is a hyperparameter that determines the size of the steps taken during optimization. It influences the convergence speed and stability of the optimization process.\n",
    "\n",
    "Impact on Convergence:\n",
    "\n",
    "Large Learning Rates: A large learning rate can cause the optimizer to overshoot the minimum, leading to oscillations or divergence.\n",
    "Small Learning Rates: A small learning rate may result in slow convergence or getting stuck in local minima.\n",
    "Equation:\n",
    "�\n",
    "�\n",
    "+\n",
    "1\n",
    "=\n",
    "�\n",
    "�\n",
    "−\n",
    "�\n",
    "⋅\n",
    "∇\n",
    "�\n",
    "(\n",
    "�\n",
    "�\n",
    ")\n",
    "θ \n",
    "t+1\n",
    "​\n",
    " =θ \n",
    "t\n",
    "​\n",
    " −α⋅∇J(θ \n",
    "t\n",
    "​\n",
    " )\n",
    "\n",
    "where:\n",
    "\n",
    "�\n",
    "α is the learning rate,\n",
    "∇\n",
    "�\n",
    "(\n",
    "�\n",
    "�\n",
    ")\n",
    "∇J(θ \n",
    "t\n",
    "​\n",
    " ) is the gradient of the cost function at time step \n",
    "�\n",
    "t,\n",
    "�\n",
    "�\n",
    "θ \n",
    "t\n",
    "​\n",
    "  is the parameter vector at time step \n",
    "�\n",
    "t.\n",
    "Combined Impact:\n",
    "Balancing Act: The choice of learning rate and momentum involves a delicate balancing act. A too-high learning rate, combined with momentum, may lead to overshooting, while a too-low learning rate can result in slow convergence.\n",
    "Improved Convergence: When properly tuned, the combination of momentum and learning rate can significantly improve convergence, allowing the optimizer to navigate through complex and noisy landscapes more effectively.\n",
    "Robustness: Adaptive learning rate methods, such as those used in optimizers like Adam, further enhance robustness by dynamically adjusting the learning rate based on the historical behavior of the optimization process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44e63504-a0e8-4729-9bd8-7e2576e6e9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Q-2 optimizers techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac614f3b-2b61-4625-9a99-534ccaae4dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "5)Stochastic Gradient Descent (SGD):\n",
    "Definition: Stochastic Gradient Descent (SGD) is a variant of the traditional gradient descent optimization algorithm. While conventional gradient descent computes the gradient of the entire dataset to update the model parameters, SGD takes a different approach. Instead of using the complete dataset, it randomly selects a single data point or a small batch of data points to compute the gradient and update the model parameters.\n",
    "\n",
    "Advantages of SGD Compared to Traditional Gradient Descent:\n",
    "Computational Efficiency:\n",
    "\n",
    "Advantage: SGD is computationally more efficient since it only requires a subset of the data for each update. This is particularly advantageous when dealing with large datasets.\n",
    "Explanation: By using mini-batches or even single data points, SGD avoids the computational burden of processing the entire dataset, leading to faster iterations.\n",
    "Faster Convergence:\n",
    "\n",
    "Advantage: SGD can converge faster than traditional gradient descent.\n",
    "Explanation: The noisy updates introduced by the stochastic nature of the process can help escape local minima and navigate through rugged optimization landscapes more efficiently.\n",
    "Memory Efficiency:\n",
    "\n",
    "Advantage: Requires less memory compared to batch gradient descent.\n",
    "Explanation: Storing and computing gradients for the entire dataset can be memory-intensive. SGD, by working with mini-batches or individual data points, reduces memory requirements.\n",
    "Regularization Effect:\n",
    "\n",
    "Advantage: The inherent noise in SGD acts as a form of regularization.\n",
    "Explanation: The randomness in selecting data points for updates introduces fluctuations in the optimization process, which can help prevent overfitting and contribute to better generalization.\n",
    "Limitations of SGD:\n",
    "Noisy Updates:\n",
    "\n",
    "Limitation: The stochastic nature of the updates introduces noise, which can cause oscillations in the convergence path.\n",
    "Mitigation: Techniques such as learning rate schedules and momentum can help mitigate the noise and stabilize the convergence.\n",
    "Learning Rate Tuning:\n",
    "\n",
    "Limitation: Choosing an appropriate learning rate becomes crucial in SGD.\n",
    "Mitigation: Learning rate schedules or adaptive learning rate methods (e.g., AdaGrad, RMSprop, Adam) can be employed to dynamically adjust the learning rate during training.\n",
    "Potential for Convergence to Suboptimal Solutions:\n",
    "\n",
    "Limitation: The randomness in selecting data points may cause the algorithm to converge to suboptimal solutions.\n",
    "Mitigation: Techniques like annealing the learning rate or using more sophisticated optimization algorithms can help mitigate this risk.\n",
    "Scenarios Where SGD is Most Suitable:\n",
    "Large Datasets:\n",
    "\n",
    "SGD is particularly well-suited for training on large datasets where computing the gradient for the entire dataset in each iteration is computationally expensive.\n",
    "Online Learning:\n",
    "\n",
    "When new data becomes available incrementally, SGD allows for online learning by updating the model parameters on the fly as new data points arrive.\n",
    "Non-Convex Optimization:\n",
    "\n",
    "In non-convex optimization landscapes, where there are many local minima, SGD's stochastic updates can help escape from suboptimal solutions and explore the parameter space more effectively.\n",
    "Parallelization:\n",
    "\n",
    "SGD can be parallelized efficiently, making it suitable for distributed computing environments.\n",
    "In summary, SGD is a powerful optimization algorithm that offers computational and memory efficiency, especially in scenarios with large datasets. While it has certain limitations, proper tuning and the use of advanced optimization techniques can make SGD a robust choice for training machine learning models, particularly in the era of deep learning.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244d8c38-e56b-474c-9927-ba06d913fba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "6)Adam Optimizer:\n",
    "Concept:\n",
    "Adam (short for Adaptive Moment Estimation) is an optimization algorithm that combines the concepts of momentum and adaptive learning rates to improve the efficiency of the optimization process. It was introduced to address some limitations of other optimization algorithms, such as SGD with momentum and AdaGrad.\n",
    "\n",
    "Key Components:\n",
    "\n",
    "Momentum:\n",
    "\n",
    "Adam incorporates the idea of momentum to accelerate convergence. It maintains a moving average of past gradients similar to SGD with momentum.\n",
    "Adaptive Learning Rates:\n",
    "\n",
    "Adam dynamically adjusts the learning rates for each parameter based on the historical gradients. It calculates separate adaptive learning rates for each parameter, which helps in dealing with sparse features or parameters that have different scales.\n",
    "Bias Correction:\n",
    "\n",
    "Adam includes a bias correction step to account for the fact that the moving averages are initialized with zeros. This correction is particularly important in the early stages of training when the moving averages are biased towards zero.\n",
    "Mathematical Formulation:\n",
    "\n",
    "The parameter update rule for Adam is given by:\n",
    "\n",
    "�\n",
    "�\n",
    "=\n",
    "�\n",
    "1\n",
    "⋅\n",
    "�\n",
    "�\n",
    "−\n",
    "1\n",
    "+\n",
    "(\n",
    "1\n",
    "−\n",
    "�\n",
    "1\n",
    ")\n",
    "⋅\n",
    "∇\n",
    "�\n",
    "(\n",
    "�\n",
    "�\n",
    ")\n",
    "m \n",
    "t\n",
    "​\n",
    " =β \n",
    "1\n",
    "​\n",
    " ⋅m \n",
    "t−1\n",
    "​\n",
    " +(1−β \n",
    "1\n",
    "​\n",
    " )⋅∇J(θ \n",
    "t\n",
    "​\n",
    " )\n",
    "�\n",
    "�\n",
    "=\n",
    "�\n",
    "2\n",
    "⋅\n",
    "�\n",
    "�\n",
    "−\n",
    "1\n",
    "+\n",
    "(\n",
    "1\n",
    "−\n",
    "�\n",
    "2\n",
    ")\n",
    "⋅\n",
    "(\n",
    "∇\n",
    "�\n",
    "(\n",
    "�\n",
    "�\n",
    ")\n",
    ")\n",
    "2\n",
    "v \n",
    "t\n",
    "​\n",
    " =β \n",
    "2\n",
    "​\n",
    " ⋅v \n",
    "t−1\n",
    "​\n",
    " +(1−β \n",
    "2\n",
    "​\n",
    " )⋅(∇J(θ \n",
    "t\n",
    "​\n",
    " )) \n",
    "2\n",
    " \n",
    "�\n",
    "^\n",
    "�\n",
    "=\n",
    "�\n",
    "�\n",
    "1\n",
    "−\n",
    "�\n",
    "1\n",
    "�\n",
    "m\n",
    "^\n",
    "  \n",
    "t\n",
    "​\n",
    " = \n",
    "1−β \n",
    "1\n",
    "t\n",
    "​\n",
    " \n",
    "m \n",
    "t\n",
    "​\n",
    " \n",
    "​\n",
    " \n",
    "�\n",
    "^\n",
    "�\n",
    "=\n",
    "�\n",
    "�\n",
    "1\n",
    "−\n",
    "�\n",
    "2\n",
    "�\n",
    "v\n",
    "^\n",
    "  \n",
    "t\n",
    "​\n",
    " = \n",
    "1−β \n",
    "2\n",
    "t\n",
    "​\n",
    " \n",
    "v \n",
    "t\n",
    "​\n",
    " \n",
    "​\n",
    " \n",
    "�\n",
    "�\n",
    "+\n",
    "1\n",
    "=\n",
    "�\n",
    "�\n",
    "−\n",
    "�\n",
    "⋅\n",
    "�\n",
    "^\n",
    "�\n",
    "�\n",
    "^\n",
    "�\n",
    "+\n",
    "�\n",
    "θ \n",
    "t+1\n",
    "​\n",
    " =θ \n",
    "t\n",
    "​\n",
    " −α⋅ \n",
    "v\n",
    "^\n",
    "  \n",
    "t\n",
    "​\n",
    " \n",
    "​\n",
    " +ϵ\n",
    "m\n",
    "^\n",
    "  \n",
    "t\n",
    "​\n",
    " \n",
    "​\n",
    " \n",
    "\n",
    "where:\n",
    "\n",
    "�\n",
    "�\n",
    "θ \n",
    "t\n",
    "​\n",
    "  is the parameter vector at time step \n",
    "�\n",
    "t,\n",
    "∇\n",
    "�\n",
    "(\n",
    "�\n",
    "�\n",
    ")\n",
    "∇J(θ \n",
    "t\n",
    "​\n",
    " ) is the gradient of the cost function at time step \n",
    "�\n",
    "t,\n",
    "�\n",
    "α is the learning rate,\n",
    "�\n",
    "1\n",
    "β \n",
    "1\n",
    "​\n",
    "  and \n",
    "�\n",
    "2\n",
    "β \n",
    "2\n",
    "​\n",
    "  are exponential decay rates for the moment estimates,\n",
    "�\n",
    "�\n",
    "m \n",
    "t\n",
    "​\n",
    "  is the first moment (mean) estimate,\n",
    "�\n",
    "�\n",
    "v \n",
    "t\n",
    "​\n",
    "  is the second moment (uncentered variance) estimate,\n",
    "�\n",
    "^\n",
    "�\n",
    "m\n",
    "^\n",
    "  \n",
    "t\n",
    "​\n",
    "  and \n",
    "�\n",
    "^\n",
    "�\n",
    "v\n",
    "^\n",
    "  \n",
    "t\n",
    "​\n",
    "  are the bias-corrected moment estimates,\n",
    "�\n",
    "ϵ is a small constant to prevent division by zero.\n",
    "Benefits of Adam Optimizer:\n",
    "Adaptive Learning Rates:\n",
    "\n",
    "Adam adapts the learning rates for each parameter individually based on the historical gradients, which can be beneficial for dealing with features that have different scales.\n",
    "Efficient in Sparse Gradients:\n",
    "\n",
    "The adaptive learning rate mechanism in Adam makes it well-suited for problems with sparse gradients, common in natural language processing and other domains.\n",
    "Combination of Momentum and Adaptiveness:\n",
    "\n",
    "Adam combines the benefits of momentum, which helps accelerate convergence, with adaptive learning rates, which helps handle different scales and sparse gradients.\n",
    "Effective in a Wide Range of Applications:\n",
    "\n",
    "Adam has shown effectiveness in a variety of deep learning applications and is widely used in practice.\n",
    "Potential Drawbacks:\n",
    "Sensitivity to Hyperparameters:\n",
    "\n",
    "Adam has hyperparameters (\n",
    "�\n",
    "α, \n",
    "�\n",
    "1\n",
    "β \n",
    "1\n",
    "​\n",
    " , \n",
    "�\n",
    "2\n",
    "β \n",
    "2\n",
    "​\n",
    " , and \n",
    "�\n",
    "ϵ), and its performance can be sensitive to their values. Improper tuning may lead to suboptimal convergence.\n",
    "Memory Requirements:\n",
    "\n",
    "Adam maintains moving averages for each parameter, which can result in higher memory requirements compared to simpler optimizers like SGD.\n",
    "Not Always Superior:\n",
    "\n",
    "While Adam is a popular choice, it may not always outperform other optimizers in every scenario. Its effectiveness depends on the nature of the data and the problem at hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf4dcc4-f538-4305-981e-99e9152c8e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "7)RMSprop Optimizer:\n",
    "RMSprop (Root Mean Square Propagation) is an optimization algorithm designed to address challenges associated with adaptive learning rates in the context of training machine learning models. The primary goal of RMSprop is to normalize the learning rates for different parameters based on the historical magnitudes of their gradients. This helps to overcome issues related to slow convergence or oscillations in optimization.\n",
    "\n",
    "Key Components:\n",
    "\n",
    "Adaptive Learning Rates:\n",
    "\n",
    "RMSprop adapts the learning rates for each parameter individually based on the magnitude of the gradients. It maintains a running average of the squared gradients for each parameter.\n",
    "Smoothing Mechanism:\n",
    "\n",
    "RMSprop incorporates a smoothing mechanism by using an exponential moving average of squared gradients, which helps prevent the learning rates from oscillating too much.\n",
    "Mathematical Formulation:\n",
    "\n",
    "The parameter update rule for RMSprop is given by:\n",
    "\n",
    "�\n",
    "[\n",
    "�\n",
    "2\n",
    "]\n",
    "�\n",
    "=\n",
    "�\n",
    "⋅\n",
    "�\n",
    "[\n",
    "�\n",
    "2\n",
    "]\n",
    "�\n",
    "−\n",
    "1\n",
    "+\n",
    "(\n",
    "1\n",
    "−\n",
    "�\n",
    ")\n",
    "⋅\n",
    "(\n",
    "∇\n",
    "�\n",
    "(\n",
    "�\n",
    "�\n",
    ")\n",
    ")\n",
    "2\n",
    "E[g \n",
    "2\n",
    " ] \n",
    "t\n",
    "​\n",
    " =β⋅E[g \n",
    "2\n",
    " ] \n",
    "t−1\n",
    "​\n",
    " +(1−β)⋅(∇J(θ \n",
    "t\n",
    "​\n",
    " )) \n",
    "2\n",
    " \n",
    "�\n",
    "�\n",
    "+\n",
    "1\n",
    "=\n",
    "�\n",
    "�\n",
    "−\n",
    "�\n",
    "�\n",
    "[\n",
    "�\n",
    "2\n",
    "]\n",
    "�\n",
    "+\n",
    "�\n",
    "⋅\n",
    "∇\n",
    "�\n",
    "(\n",
    "�\n",
    "�\n",
    ")\n",
    "θ \n",
    "t+1\n",
    "​\n",
    " =θ \n",
    "t\n",
    "​\n",
    " − \n",
    "E[g \n",
    "2\n",
    " ] \n",
    "t\n",
    "​\n",
    " +ϵ\n",
    "​\n",
    " \n",
    "α\n",
    "​\n",
    " ⋅∇J(θ \n",
    "t\n",
    "​\n",
    " )\n",
    "\n",
    "where:\n",
    "\n",
    "�\n",
    "�\n",
    "θ \n",
    "t\n",
    "​\n",
    "  is the parameter vector at time step \n",
    "�\n",
    "t,\n",
    "∇\n",
    "�\n",
    "(\n",
    "�\n",
    "�\n",
    ")\n",
    "∇J(θ \n",
    "t\n",
    "​\n",
    " ) is the gradient of the cost function at time step \n",
    "�\n",
    "t,\n",
    "�\n",
    "[\n",
    "�\n",
    "2\n",
    "]\n",
    "�\n",
    "E[g \n",
    "2\n",
    " ] \n",
    "t\n",
    "​\n",
    "  is the running average of squared gradients at time step \n",
    "�\n",
    "t,\n",
    "�\n",
    "α is the learning rate,\n",
    "�\n",
    "β is the decay rate for the running average,\n",
    "�\n",
    "ϵ is a small constant to prevent division by zero.\n",
    "Comparison with Adam Optimizer:\n",
    "Similarities:\n",
    "\n",
    "Both RMSprop and Adam are adaptive learning rate optimizers, aiming to improve the convergence of optimization algorithms by adjusting learning rates based on the historical behavior of gradients.\n",
    "Differences:\n",
    "\n",
    "Momentum:\n",
    "\n",
    "Adam: Includes a momentum term that accumulates past gradients.\n",
    "RMSprop: Does not have an explicit momentum term. It relies on a simple moving average of squared gradients to adjust learning rates.\n",
    "Adaptive Learning Rate Formulation:\n",
    "\n",
    "Adam: Uses both first and second moment estimates (momentum and uncentered variance) in the adaptive learning rate calculation.\n",
    "RMSprop: Utilizes only the squared gradients in the adaptive learning rate calculation.\n",
    "Bias Correction:\n",
    "\n",
    "Adam: Incorporates bias correction for the moving averages to account for their initialization with zeros.\n",
    "RMSprop: Typically does not include explicit bias correction.\n",
    "Relative Strengths:\n",
    "\n",
    "Adam:\n",
    "\n",
    "Adam is often considered more sophisticated due to its combination of momentum and adaptive learning rates. It may perform well in a wide range of scenarios and is widely used in practice.\n",
    "RMSprop:\n",
    "\n",
    "RMSprop can be computationally less expensive as it involves simpler calculations compared to Adam. It may perform well in scenarios where computational resources are limited.\n",
    "Relative Weaknesses:\n",
    "\n",
    "Adam:\n",
    "\n",
    "Adam may require more memory due to the storage of additional moving averages, making it less memory-efficient compared to RMSprop.\n",
    "RMSprop:\n",
    "\n",
    "RMSprop might be sensitive to the choice of hyperparameters, and the absence of explicit bias correction could impact its performance in the early stages of training.\n",
    "Guidelines for Choosing:\n",
    "\n",
    "In practice, the choice between Adam and RMSprop may depend on the specific characteristics of the problem, the dataset, and the computational resources available.\n",
    "It is recommended to experiment with both optimizers and fine-tune hyperparameters to find the best-performing option for a particular task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd4459e0-6a24-40fb-aff2-5950684250c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Q-8 applying optimizers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c0adfb-66ab-4228-be7d-e03de33079d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.15.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.2 MB)\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m459.9/475.2 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m"
     ]
    }
   ],
   "source": [
    "pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "201def7d-1c8b-422b-88e3-68975935d262",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layers, models\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mnist\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load and preprocess the dataset (MNIST as an example)\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "train_images = train_images.reshape((60000, 28, 28, 1)).astype(\"float32\") / 255\n",
    "test_images = test_images.reshape((10000, 28, 28, 1)).astype(\"float32\") / 255\n",
    "train_labels = tf.keras.utils.to_categorical(train_labels)\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels)\n",
    "\n",
    "# Define a simple CNN model\n",
    "def build_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation=\"relu\", input_shape=(28, 28, 1)))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(10, activation=\"softmax\"))\n",
    "    return model\n",
    "\n",
    "# Function to train the model with different optimizers\n",
    "def train_model(optimizer, epochs=10):\n",
    "    model = build_model()\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss=\"categorical_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "    \n",
    "    history = model.fit(train_images, train_labels, epochs=epochs, validation_data=(test_images, test_labels), verbose=0)\n",
    "    \n",
    "    return history\n",
    "\n",
    "# Train the model with different optimizers\n",
    "sgd_history = train_model(SGD(learning_rate=0.01), epochs=10)\n",
    "adam_history = train_model(Adam(learning_rate=0.001), epochs=10)\n",
    "rmsprop_history = train_model(RMSprop(learning_rate=0.001), epochs=10)\n",
    "\n",
    "# Plot the training history\n",
    "plt.plot(sgd_history.history[\"accuracy\"], label=\"SGD\")\n",
    "plt.plot(adam_history.history[\"accuracy\"], label=\"Adam\")\n",
    "plt.plot(rmsprop_history.history[\"accuracy\"], label=\"RMSprop\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55775cf-86b2-4e11-8164-4fb041b8ce2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1db8da-5daa-4810-9e5c-2c450b7693b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994b6612-9170-4df0-9ed8-1a64962ffae7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccf45f4-f9a3-4a1e-bc2d-2f385b0ea2d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645cc984-d8d7-420f-890f-19845e9d3e8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf36155-ff63-48dc-9bc3-c02fb130f9c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2917e81a-4e17-4859-8479-f0993291888d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eff3bd7-acd3-48ca-9693-f94e3a42921a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3149510a-3cfb-4677-945d-78eb5f068480",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4134219-80cb-46f5-b580-13ebf65c0a7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
